{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('F:/hotel_review.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nice hotel expensive parking got good deal sta...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ok nothing special charge diamond member hilto...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nice rooms not 4* experience hotel monaco seat...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>unique, great stay, wonderful time hotel monac...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>great stay great stay, went seahawk game aweso...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20486</th>\n",
       "      <td>best kept secret 3rd time staying charm, not 5...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20487</th>\n",
       "      <td>great location price view hotel great quick pl...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20488</th>\n",
       "      <td>ok just looks nice modern outside, desk staff ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20489</th>\n",
       "      <td>hotel theft ruined vacation hotel opened sept ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20490</th>\n",
       "      <td>people talking, ca n't believe excellent ratin...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20491 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Review  Rating\n",
       "0      nice hotel expensive parking got good deal sta...       4\n",
       "1      ok nothing special charge diamond member hilto...       2\n",
       "2      nice rooms not 4* experience hotel monaco seat...       3\n",
       "3      unique, great stay, wonderful time hotel monac...       5\n",
       "4      great stay great stay, went seahawk game aweso...       5\n",
       "...                                                  ...     ...\n",
       "20486  best kept secret 3rd time staying charm, not 5...       5\n",
       "20487  great location price view hotel great quick pl...       4\n",
       "20488  ok just looks nice modern outside, desk staff ...       2\n",
       "20489  hotel theft ruined vacation hotel opened sept ...       1\n",
       "20490  people talking, ca n't believe excellent ratin...       2\n",
       "\n",
       "[20491 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20491 entries, 0 to 20490\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Review  20491 non-null  object\n",
      " 1   Rating  20491 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 320.3+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text):\n",
    "    text = re.sub(r'\\d+', ' ', text)\n",
    "    text = text.split()\n",
    "    text = \" \".join([word for word in text if word.lower().strip() not in stop_words])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = data['Review'].apply(process_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 10000\n",
    "\n",
    "tokenizer = Tokenizer(num_words=num_words)\n",
    "tokenizer.fit_on_texts(reviews)\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sequence length: 1833\n"
     ]
    }
   ],
   "source": [
    "max_seq_length = np.max(list(map(lambda x: len(x), sequences)))\n",
    "\n",
    "print(\"Max sequence length:\", max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = pad_sequences(sequences, maxlen=max_seq_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   8,    1,  174, ...,    0,    0,    0],\n",
       "       [ 139,  136,  262, ...,    0,    0,    0],\n",
       "       [   8,    9,   76, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [ 139,  733,    8, ...,    0,    0,    0],\n",
       "       [   1, 3785, 2479, ...,    0,    0,    0],\n",
       "       [  27, 1156,  187, ...,    0,    0,    0]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    9054\n",
       "4    6039\n",
       "3    2184\n",
       "2    1793\n",
       "1    1421\n",
       "Name: Rating, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels = np.array(data['Rating'].apply(lambda x: 1 if x == 5 else 0))\n",
    "labels=np.array(data['Rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 2, 3, ..., 2, 1, 2], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs, test_inputs, train_labels, test_labels = train_test_split(inputs, labels, train_size=0.7, random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model-02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 1833)]            0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 1833, 16)          160000    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 1833, 32)         3264      \n",
      " l)                                                              \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 58656)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 58657     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 221,921\n",
      "Trainable params: 221,921\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 16\n",
    "\n",
    "inputs = tf.keras.Input(shape=(max_seq_length,))\n",
    "\n",
    "embedding = tf.keras.layers.Embedding(\n",
    "    input_dim=num_words,\n",
    "    output_dim=embedding_dim,\n",
    "    input_length=max_seq_length\n",
    ")(inputs)\n",
    "\n",
    "gru = tf.keras.layers.Bidirectional(\n",
    "    tf.keras.layers.GRU(16, return_sequences=True)\n",
    ")(embedding)\n",
    "\n",
    "flatten = tf.keras.layers.Flatten()(gru)\n",
    "\n",
    "outputs = tf.keras.layers.Dense(1, activation='softmax')(flatten)\n",
    "\n",
    "\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "144/144 [==============================] - 172s 1s/step - loss: -14544.8311 - accuracy: 0.0697 - auc: 0.0000e+00 - val_loss: -34814.4219 - val_accuracy: 0.0742 - val_auc: 0.0000e+00\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 178s 1s/step - loss: -50335.9336 - accuracy: 0.0697 - auc: 0.0000e+00 - val_loss: -64436.4219 - val_accuracy: 0.0742 - val_auc: 0.0000e+00\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 168s 1s/step - loss: -78616.7109 - accuracy: 0.0697 - auc: 0.0000e+00 - val_loss: -91460.9766 - val_accuracy: 0.0742 - val_auc: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=[\n",
    "        'accuracy',\n",
    "        tf.keras.metrics.AUC(name='auc')\n",
    "    ]\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_inputs,\n",
    "    train_labels,\n",
    "    validation_split=0.2,\n",
    "    batch_size=80,\n",
    "    epochs=5,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_accuracy',\n",
    "            patience=2,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193/193 [==============================] - 27s 140ms/step - loss: -35155.2812 - accuracy: 0.0664 - auc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[-35155.28125, 0.06636304408311844, 0.0]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_inputs, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model03-Autokeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting autokeras\n",
      "  Using cached autokeras-1.0.19-py3-none-any.whl (162 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\sarvesh s\\anaconda3\\lib\\site-packages (from autokeras) (1.2.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\sarvesh s\\anaconda3\\lib\\site-packages (from autokeras) (20.9)\n",
      "Requirement already satisfied: keras-tuner>=1.1.0 in c:\\users\\sarvesh s\\anaconda3\\lib\\site-packages (from autokeras) (1.1.3.dev0)\n",
      "Requirement already satisfied: tensorflow>=2.8.0 in c:\\users\\sarvesh s\\anaconda3\\lib\\site-packages (from autokeras) (2.9.1)\n",
      "Requirement already satisfied: tensorboard in c:\\users\\sarvesh s\\anaconda3\\lib\\site-packages (from keras-tuner>=1.1.0->autokeras) (2.9.1)\n",
      "Requirement already satisfied: requests in c:\\users\\sarvesh s\\anaconda3\\lib\\site-packages (from keras-tuner>=1.1.0->autokeras) (2.28.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\sarvesh s\\anaconda3\\lib\\site-packages (from keras-tuner>=1.1.0->autokeras) (1.22.4)\n",
      "Requirement already satisfied: ipython in c:\\users\\sarvesh s\\anaconda3\\lib\\site-packages (from keras-tuner>=1.1.0->autokeras) (7.22.0)\n",
      "Requirement already satisfied: kt-legacy in c:\\users\\sarvesh s\\anaconda3\\lib\\site-packages (from keras-tuner>=1.1.0->autokeras) (1.0.4)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\sarvesh s\\anaconda3\\lib\\site-packages (from tensorflow>=2.8.0->autokeras) (2.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\sarvesh s\\anaconda3\\lib\\site-packages (from tensorflow>=2.8.0->autokeras) (3.7.4.3)\n",
      "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in c:\\users\\sarvesh s\\anaconda3\\lib\\site-packages (from tensorflow>=2.8.0->autokeras) (2.9.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\sarvesh s\\anaconda3\\lib\\site-packages (from tensorflow>=2.8.0->autokeras) (63.1.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\sarvesh s\\anaconda3\\lib\\site-packages (from tensorflow>=2.8.0->autokeras) (1.1.2)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\sarvesh s\\anaconda3\\lib\\site-packages (from tensorflow>=2.8.0->autokeras) (0.2.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\sarvesh s\\anaconda3\\lib\\site-packages (from tensorflow>=2.8.0->autokeras) (3.19.4)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\sarvesh s\\anaconda3\\lib\\site-packages (from tensorflow>=2.8.0->autokeras) (0.4.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\sarvesh s\\anaconda3\\lib\\site-packages (from tensorflow>=2.8.0->autokeras) (1.12.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\sarvesh s\\anaconda3\\lib\\site-packages (from tensorflow>=2.8.0->autokeras) (1.1.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\sarvesh s\\anaconda3\\lib\\site-packages (from tensorflow>=2.8.0->autokeras) (3.3.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\sarvesh s\\anaconda3\\lib\\site-packages (from tensorflow>=2.8.0->autokeras) (0.26.0)\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in c:\\users\\sarvesh s\\anaconda3\\lib\\site-packages (from tensorflow>=2.8.0->autokeras) (1.12)\n",
      "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in c:\\users\\sarvesh s\\anaconda3\\lib\\site-packages (from tensorflow>=2.8.0->autokeras) (2.9.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\sarvesh s\\anaconda3\\lib\\site-packages (from tensorflow>=2.8.0->autokeras) (14.0.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\sarvesh s\\anaconda3\\lib\\site-packages (from tensorflow>=2.8.0->autokeras) (1.6.3)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\sarvesh s\\anaconda3\\lib\\site-packages (from tensorflow>=2.8.0->autokeras) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\sarvesh s\\anaconda3\\lib\\site-packages (from tensorflow>=2.8.0->autokeras) (1.1.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\sarvesh s\\anaconda3\\lib\\site-packages (from tensorflow>=2.8.0->autokeras) (1.36.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\sarvesh s\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow>=2.8.0->autokeras) (0.37.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\sarvesh s\\anaconda3\\lib\\site-packages (from tensorboard->keras-tuner>=1.1.0->autokeras) (0.6.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\sarvesh s\\anaconda3\\lib\\site-packages (from tensorboard->keras-tuner>=1.1.0->autokeras) (3.3.4)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\sarvesh s\\anaconda3\\lib\\site-packages (from tensorboard->keras-tuner>=1.1.0->autokeras) (2.1.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\sarvesh s\\anaconda3\\lib\\site-packages (from tensorboard->keras-tuner>=1.1.0->autokeras) (0.4.4)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\sarvesh s\\anaconda3\\lib\\site-packages (from tensorboard->keras-tuner>=1.1.0->autokeras) (1.8.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\sarvesh s\\anaconda3\\lib\\site-packages (from tensorboard->keras-tuner>=1.1.0->autokeras) (2.9.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\sarvesh s\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner>=1.1.0->autokeras) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\sarvesh s\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner>=1.1.0->autokeras) (5.2.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\sarvesh s\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner>=1.1.0->autokeras) (4.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\sarvesh s\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner>=1.1.0->autokeras) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\sarvesh s\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->keras-tuner>=1.1.0->autokeras) (0.4.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sarvesh s\\anaconda3\\lib\\site-packages (from requests->keras-tuner>=1.1.0->autokeras) (2022.6.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sarvesh s\\anaconda3\\lib\\site-packages (from requests->keras-tuner>=1.1.0->autokeras) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\sarvesh s\\anaconda3\\lib\\site-packages (from requests->keras-tuner>=1.1.0->autokeras) (2.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\sarvesh s\\anaconda3\\lib\\site-packages (from requests->keras-tuner>=1.1.0->autokeras) (1.26.10)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\sarvesh s\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner>=1.1.0->autokeras) (3.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\sarvesh s\\anaconda3\\lib\\site-packages (from ipython->keras-tuner>=1.1.0->autokeras) (0.4.4)\n",
      "Requirement already satisfied: decorator in c:\\users\\sarvesh s\\anaconda3\\lib\\site-packages (from ipython->keras-tuner>=1.1.0->autokeras) (5.0.6)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\sarvesh s\\anaconda3\\lib\\site-packages (from ipython->keras-tuner>=1.1.0->autokeras) (0.7.5)\n",
      "Requirement already satisfied: traitlets>=4.2 in c:\\users\\sarvesh s\\anaconda3\\lib\\site-packages (from ipython->keras-tuner>=1.1.0->autokeras) (5.3.0)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\sarvesh s\\anaconda3\\lib\\site-packages (from ipython->keras-tuner>=1.1.0->autokeras) (0.17.2)\n",
      "Requirement already satisfied: pygments in c:\\users\\sarvesh s\\anaconda3\\lib\\site-packages (from ipython->keras-tuner>=1.1.0->autokeras) (2.12.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\sarvesh s\\anaconda3\\lib\\site-packages (from ipython->keras-tuner>=1.1.0->autokeras) (3.0.30)\n",
      "Requirement already satisfied: backcall in c:\\users\\sarvesh s\\anaconda3\\lib\\site-packages (from ipython->keras-tuner>=1.1.0->autokeras) (0.2.0)\n",
      "Requirement already satisfied: parso<0.8.0,>=0.7.0 in c:\\users\\sarvesh s\\anaconda3\\lib\\site-packages (from jedi>=0.16->ipython->keras-tuner>=1.1.0->autokeras) (0.7.1)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\sarvesh s\\anaconda3\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->keras-tuner>=1.1.0->autokeras) (0.2.5)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\sarvesh s\\anaconda3\\lib\\site-packages (from packaging->autokeras) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\sarvesh s\\anaconda3\\lib\\site-packages (from pandas->autokeras) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\sarvesh s\\anaconda3\\lib\\site-packages (from pandas->autokeras) (2021.1)\n",
      "Installing collected packages: autokeras\n",
      "Successfully installed autokeras-1.0.19\n"
     ]
    }
   ],
   "source": [
    "!pip install autokeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autokeras as ak"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the data for autokeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14344"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split=round(len(data)*.70)\n",
    "split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=data['Review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=data['Rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs,test_inputs=x[:split],x[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels,test_labels=y[:split],y[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ak = np.array(train_inputs)\n",
    "y_train_ak = np.array(train_labels)\n",
    "X_test_ak = np.array(test_inputs)\n",
    "y_test_ak = np.array(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training set is used to fit the models; the validation set is used to estimate prediction error for model selection; the test set is used for assessment of the generalization error of the final chosen model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3 Complete [00h 00m 46s]\n",
      "val_loss: 1.5750421285629272\n",
      "\n",
      "Best val_loss So Far: 0.6759951114654541\n",
      "Total elapsed time: 00h 02m 53s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "449/449 [==============================] - 8s 16ms/step - loss: 1.3576 - mean_squared_error: 1.3576\n",
      "Epoch 2/10\n",
      "449/449 [==============================] - 7s 16ms/step - loss: 0.5760 - mean_squared_error: 0.5760\n",
      "Epoch 3/10\n",
      "449/449 [==============================] - 7s 16ms/step - loss: 0.4020 - mean_squared_error: 0.4020\n",
      "Epoch 4/10\n",
      "449/449 [==============================] - 7s 16ms/step - loss: 0.2797 - mean_squared_error: 0.2797\n",
      "Epoch 5/10\n",
      "449/449 [==============================] - 7s 16ms/step - loss: 0.3018 - mean_squared_error: 0.3018\n",
      "Epoch 6/10\n",
      "449/449 [==============================] - 7s 16ms/step - loss: 0.4048 - mean_squared_error: 0.4048\n",
      "Epoch 7/10\n",
      "449/449 [==============================] - 7s 16ms/step - loss: 0.4059 - mean_squared_error: 0.4059\n",
      "Epoch 8/10\n",
      "449/449 [==============================] - 7s 16ms/step - loss: 0.3189 - mean_squared_error: 0.3189\n",
      "Epoch 9/10\n",
      "449/449 [==============================] - 7s 16ms/step - loss: 0.2753 - mean_squared_error: 0.2753\n",
      "Epoch 10/10\n",
      "449/449 [==============================] - 8s 17ms/step - loss: 0.2513 - mean_squared_error: 0.2513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: .\\text_regressor\\best_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: .\\text_regressor\\best_model\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1cc973735b0>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "keras = ak.TextRegressor(overwrite=True, max_trials=3) #TextRegressor with maximum trials of 3 i.e The AutoKeras will create a maximum of 3 prediction models  \n",
    "\n",
    "keras.fit(X_train_ak, y_train_ak, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None,)]                 0         \n",
      "                                                                 \n",
      " expand_last_dim (ExpandLast  (None, 1)                0         \n",
      " Dim)                                                            \n",
      "                                                                 \n",
      " text_vectorization (TextVec  (None, 64)               0         \n",
      " torization)                                                     \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 64, 128)           640128    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64, 128)           0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 62, 32)            12320     \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 60, 32)            3104      \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 30, 32)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 28, 32)            3104      \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 26, 32)            3104      \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 13, 32)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 416)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                13344     \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 32)                0         \n",
      "                                                                 \n",
      " regression_head_1 (Dense)   (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 676,193\n",
      "Trainable params: 676,193\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Show the built models\n",
    "keras_export = keras.export_model()\n",
    "keras_export.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193/193 [==============================] - 1s 5ms/step\n",
      "193/193 [==============================] - 1s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predict the test data\n",
    "from itertools import chain\n",
    "pred_keras = keras.predict(X_test_ak)\n",
    "pred_keras = list(chain(*pred_keras))\n",
    "pred_keras2 = [i if i <= 5 else 5 for i in pred_keras]\n",
    "pred_keras2 = [i if i >= 1 else 1 for i in pred_keras2]\n",
    "pred_keras2 = [round(i) for i in pred_keras2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the RMSE\n",
    "#rmse_keras = mean_squared_error(y_test_ak, pred_keras2)**0.5\n",
    "#print('RMSE: ' + str(rmse_keras))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>183</td>\n",
       "      <td>87</td>\n",
       "      <td>34</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>151</td>\n",
       "      <td>161</td>\n",
       "      <td>110</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49</td>\n",
       "      <td>137</td>\n",
       "      <td>252</td>\n",
       "      <td>182</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>115</td>\n",
       "      <td>408</td>\n",
       "      <td>1015</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>46</td>\n",
       "      <td>330</td>\n",
       "      <td>1771</td>\n",
       "      <td>867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     1    2    3     4    5\n",
       "1  183   87   34    13    0\n",
       "2  151  161  110    50    1\n",
       "3   49  137  252   182    7\n",
       "4   11  115  408  1015  163\n",
       "5    4   46  330  1771  867"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Confusion Matrix')\n",
    "pd.DataFrame(confusion_matrix(test_labels, pred_keras2), index=[1,2,3,4,5], columns=[1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the accuracy of the sequential model is 60% and for input model(another custom model) is 50% because in the 2nd model we had less amount of layer from that we can say that the sequential model is best for this type of data and if we increase the epoch and batch size we can increase the accuracy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the autokeras tells that the this is best layer for our data and our sequential model is more are less same thats why we can get better accuracy compare to 2nd model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
